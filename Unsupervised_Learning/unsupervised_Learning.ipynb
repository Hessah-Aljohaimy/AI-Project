{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Unsupervised learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the unsupervised learning phase we choose K-means clustering algorithm.K-means is a centroid-based clustering algorithm, where we calculate the distance between each data point and a centroid to assign it to a cluster. The goal is to identify the K number of groups in the dataset.It is an iterative process of assigning each data point to the groups and slowly data points get clustered based on similar features. The objective is to minimize the sum of distances between the data points and the cluster centroid, to identify the correct group each data point should belong to.[source] \n",
    "\n",
    "[source] Sharma, N. (2023) K-means clustering explained, neptune.ai. Available at: https://neptune.ai/blog/k-means-clustering (Accessed: 19 May 2023). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings #to remove the warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/khawlahalnayel/Desktop/AI-Project/Dataset/waterQualityCleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#iris = pd.read_csv('C:\\AI-Project\\Dataset\\waterQualityCleaned.csv')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m iris \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mC:/Users/khawlahalnayel/Desktop/AI-Project/Dataset/waterQualityCleaned.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/khawlahalnayel/Desktop/AI-Project/Dataset/waterQualityCleaned.csv'"
     ]
    }
   ],
   "source": [
    "#iris = pd.read_csv('C:\\AI-Project\\Dataset\\waterQualityCleaned.csv')\n",
    "#iris = pd.read_csv('C:/Users/khawlahalnayel/Desktop/AI-Project/Dataset/waterQualityCleaned.csv')\n",
    "iris = pd.read_csv('C:/fluttergithubapp/AI-Project/AI-Project/Dataset/waterQualityCleaned.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WCSS and Elbow Method wich is used to select the good number of clusters.The elbow method is a graphical representation of finding the optimal ‘K’ in a K-means clustering. It works by finding WCSS (Within-Cluster Sum of Square) i.e. the sum of the square distance between points in a cluster and the cluster centroid.The elbow graph shows WCSS values(on the y-axis) corresponding to the different values of K(on the x-axis). When we see an elbow shape in the graph, we pick the K-value where the elbow gets created. We can call this point the Elbow point. Beyond the Elbow point, increasing the value of ‘K’ does not lead to a significant reduction in WCSS.[source]\n",
    "\n",
    "[source]Tomar, A. (2022) Stop using elbow method in k-means clustering, instead, use this!, Medium. Available at: https://towardsdatascience.com/elbow-method-is-not-sufficient-to-find-best-k-in-k-means-clustering-fc820da0631d (Accessed: 20 May 2023). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source:https://towardsdatascience.com/elbow-method-is-not-sufficient-to-find-best-k-in-k-means-clustering-fc820da0631d\n",
    "\n",
    "\n",
    "\n",
    "#install yellowbrick to vizualize the Elbow curve\n",
    "%pip install yellowbrick  \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Load the IRIS dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "km = KMeans(random_state=42)\n",
    "visualizer = KElbowVisualizer(km, k=(2,10))\n",
    " \n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the image above, we will choose 2,4 and 5 as number if cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1- K with size 2:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the features columns except the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(iris.columns)[:-2]\n",
    "\n",
    "# Get the features data\n",
    "data = iris[features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have number of cluster = 2, then we fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_kmeans = KMeans(n_clusters=2)\n",
    "data['clusters'] = clustering_kmeans.fit_predict(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have 3 or more column,we cannot visualize the clustering directly. However, we apply a Principal Component Analysis to reduce the space in 2 columns and visualize this instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_num_components = 2\n",
    "\n",
    "reduced_data = PCA(n_components=pca_num_components).fit_transform(data)\n",
    "results = pd.DataFrame(reduced_data,columns=['pca1','pca2'])\n",
    "\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", hue=data['clusters'], data=results)\n",
    "plt.title('K-means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, after we apply clustering with k=2 , we got these 2 groups. first group with orange color have pca1 from 0 to almost 1500, second group with purple color have pca1 less than 0 to -1500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2- K with size 4:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have number of cluster = 4, then we fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_kmeans = KMeans(n_clusters=4)\n",
    "data['clusters'] = clustering_kmeans.fit_predict(data)\n",
    "\n",
    "pca_num_components = 2\n",
    "\n",
    "reduced_data = PCA(n_components=pca_num_components).fit_transform(data)\n",
    "results = pd.DataFrame(reduced_data,columns=['pca1','pca2'])\n",
    "\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", hue=data['clusters'], data=results)\n",
    "plt.title('K-means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, it is better than k=2 since we can see different clusters in different location without overlapping between them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3- K with size 5:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have number of cluster = 5, then we fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_kmeans = KMeans(n_clusters=5)\n",
    "data['clusters'] = clustering_kmeans.fit_predict(data)\n",
    "\n",
    "pca_num_components = 2\n",
    "\n",
    "reduced_data = PCA(n_components=pca_num_components).fit_transform(data)\n",
    "results = pd.DataFrame(reduced_data,columns=['pca1','pca2'])\n",
    "\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", hue=data['clusters'], data=results)\n",
    "plt.title('K-means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, it is also better than k=2, and same as k=4 we can see different clusters in different location without overlapping between them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Methods**\n",
    "\n",
    "To evalute the k-means clustring we will use different methods and metrics which are Silhouette coefficient , total within-cluster sum of square , BCubed precision and recall along with visualization of each method and metric along with our obsrvation of the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Silhouette coefficient**\n",
    "\n",
    "Silhouette refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object has been classified.The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters[source]\n",
    "\n",
    "[source]Silhouette (clustering) (2023) Wikipedia. Available at: https://en.wikipedia.org/wiki/Silhouette_(clustering) (Accessed: 19 May 2023). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the silhouette algorithm.We can observe the fllowing results for each clustering values [2 ,4 ,5] :\n",
    "\n",
    "2: 0.627481431521672,\n",
    "\n",
    "4: 0.5701792797942534,\n",
    "\n",
    "5: 0.5695587418652014\n",
    "\n",
    "as the silhouette coefficient results the values from the range of -1 to +1 we can see that the k=2 provides the best silhouette coefficient value and the closest to +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silhouette_scores = dict()\n",
    "range_of_k = range(2,3)\n",
    "for k in range_of_k :\n",
    "    untrained_model = KMeans(n_clusters=k)\n",
    "    trained_model=untrained_model.fit(reduced_data)\n",
    "    cluster_labels = trained_model.labels_\n",
    "    score=silhouette_score(reduced_data, cluster_labels)\n",
    "    S_2=score\n",
    "    # silhouette_scores[k]=score\n",
    "print(\"The k=2 Silhouette scores is : \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = dict()\n",
    "range_of_k = range(4,5)\n",
    "for k in range_of_k :\n",
    "    untrained_model = KMeans(n_clusters=k)\n",
    "    trained_model=untrained_model.fit(reduced_data)\n",
    "    cluster_labels = trained_model.labels_\n",
    "    score=silhouette_score(reduced_data, cluster_labels)\n",
    "    s_4=score\n",
    "    # silhouette_scores[k]=score\n",
    "print(\"The k=4 Silhouette scores is : \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = dict()\n",
    "range_of_k = range(5,6)\n",
    "for k in range_of_k :\n",
    "    untrained_model = KMeans(n_clusters=k)\n",
    "    trained_model=untrained_model.fit(reduced_data)\n",
    "    cluster_labels = trained_model.labels_\n",
    "    score=silhouette_score(reduced_data, cluster_labels)\n",
    "    S_5=score\n",
    "    # silhouette_scores[k]=score\n",
    "print(\"The k=5 Silhouette scores is : \",score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we Visualized the results of each clustring value and as the figure shows the k=2 provides the best silhouette coefficient results and the closest value to +1.And according to the plot below we can see that k=2 has the closest value to +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source:https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "for i in [2, 3, 4, 5]:\n",
    "    '''\n",
    "    Create KMeans instance for different number of clusters\n",
    "    '''\n",
    "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "    q, mod = divmod(i, 2)\n",
    "    '''\n",
    "    Create SilhouetteVisualizer instance with KMeans instance\n",
    "    Fit the visualizer\n",
    "    '''\n",
    "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Total within-cluster sum of square**\n",
    "\n",
    "The within-cluster sum of squares is a measure of the variability of the observations within each cluster. In general, a cluster that has a small sum of squares is more compact than a cluster that has a large sum of squares. Clusters that have higher values exhibit greater variability of the observations within the cluster.[source]\n",
    "\n",
    "[source]Interpret all statistics and graphs for Cluster K-means (no date) Minitab. Available at: https://support.minitab.com/en-us/minitab/21/help-and-how-to/statistical-modeling/multivariate/how-to/cluster-k-means/interpret-the-results/all-statistics-and-graphs/#:~:text=The%20within%2Dcluster%20sum%20of%20squares%20is%20a%20measure%20of,a%20large%20sum%20of%20squares. (Accessed: 19 May 2023). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the clusters we have k = 2,4,5 each cluster provides diffrent reslutes.\n",
    "\n",
    "In k = 2 the TWSS equals to 152.347 approximately.While in k = 4 the TWSS equals to 57.22 approximately and in k = 5 the TWSS equals to 46.46 approximately.And According to the Total Within Cluster Sum of Squares the smaller the value is the more compact the cluster is and in our case k = 5 has the smallest value compared to k = 2 and k = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random dataset\n",
    "X = iris.data\n",
    "\n",
    "# Perform k-means clustering with k=2\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Calculate the total within-cluster sum of squares\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "distances = np.sum((X - centroids[labels])**2, axis=1)\n",
    "total_within_cluster_sum_of_squares = np.sum(distances)\n",
    "\n",
    "print(\" Total within cluster sum of squares for (k = 2): \",total_within_cluster_sum_of_squares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random dataset\n",
    "X = iris.data\n",
    "\n",
    "# Perform k-means clustering with k=4\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Calculate the total within-cluster sum of squares\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "distances = np.sum((X - centroids[labels])**2, axis=1)\n",
    "total_within_cluster_sum_of_squares = np.sum(distances)\n",
    "\n",
    "print(\" Total within cluster sum of squares for (k = 4): \",total_within_cluster_sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random dataset\n",
    "X = iris.data\n",
    "\n",
    "# Perform k-means clustering with k=5\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Calculate the total within-cluster sum of squares\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "distances = np.sum((X - centroids[labels])**2, axis=1)\n",
    "total_within_cluster_sum_of_squares = np.sum(distances)\n",
    "\n",
    "print(\" Total within cluster sum of squares for (k = 5): \",total_within_cluster_sum_of_squares)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize with k=2 as it shows the centroid along with the clustring values in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize with k=4 as it shows the centroid along with the clustring values in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize with k=5 as it shows the centroid along with the clustring values in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.BCubed precision and recall**\n",
    "\n",
    "BCubed metrics decompose the evaluation process estimating the precision and recall associated to each item in the distribution. The item precision represents how many items in the same cluster belong to its category. Symmetrically, the recall associated to one item represents how many items from its category appear in its cluster[source]\n",
    "\n",
    "[source]Interpret all statistics and graphs for Cluster K-means (no date a) Minitab. Available at: https://support.minitab.com/en-us/minitab/21/help-and-how-to/statistical-modeling/multivariate/how-to/cluster-k-means/interpret-the-results/all-statistics-and-graphs/#:~:text=The%20within%2Dcluster%20sum%20of%20squares%20is%20a%20measure%20of,a%20large%20sum%20of%20squares. (Accessed: 19 May 2023). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For K = 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features from the dataset\n",
    "X = iris.data\n",
    "\n",
    "# Extract the true cluster labels from the dataset\n",
    "y_true = iris.target\n",
    "\n",
    "# Perform k-means clustering with k=2\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Extract the predicted cluster labels from the KMeans object\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Calculate BCubed precision\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "print('BCubed precision for (K = 2):', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features from the dataset\n",
    "X = iris.data\n",
    "\n",
    "# Extract the true cluster labels from the dataset\n",
    "y_true = iris.target\n",
    "\n",
    "# Perform k-means clustering with k=2\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Extract the predicted cluster labels from the KMeans object\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Calculate BCubed recall\n",
    "labels = np.unique(y_true)\n",
    "recall = 0\n",
    "for label in labels:\n",
    "    idx = np.where(y_true == label)[0]\n",
    "    recall += np.sum(y_true[idx] == y_pred[idx]) / len(idx)\n",
    "recall /= len(labels)\n",
    "print('BCubed recall for (K = 2):', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For K = 4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features from the dataset\n",
    "X = iris.data\n",
    "\n",
    "# Extract the true cluster labels from the dataset\n",
    "y_true = iris.target\n",
    "\n",
    "# Perform k-means clustering with k=4\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Extract the predicted cluster labels from the KMeans object\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Calculate BCubed precision\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "print('BCubed precision for (K = 4):', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features from the dataset\n",
    "X = iris.data\n",
    "\n",
    "# Extract the true cluster labels from the dataset\n",
    "y_true = iris.target\n",
    "\n",
    "# Perform k-means clustering with k=4\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Extract the predicted cluster labels from the KMeans object\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Calculate BCubed recall\n",
    "labels = np.unique(y_true)\n",
    "recall = 0\n",
    "for label in labels:\n",
    "    idx = np.where(y_true == label)[0]\n",
    "    recall += np.sum(y_true[idx] == y_pred[idx]) / len(idx)\n",
    "recall /= len(labels)\n",
    "print('BCubed recall for (K = 4):', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For K=5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features from the dataset\n",
    "X = iris.data\n",
    "\n",
    "# Extract the true cluster labels from the dataset\n",
    "y_true = iris.target\n",
    "\n",
    "# Perform k-means clustering with k=5\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Extract the predicted cluster labels from the KMeans object\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Calculate BCubed precision\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "print('BCubed precision for (K = 5):', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features from the dataset\n",
    "X = iris.data\n",
    "\n",
    "# Extract the true cluster labels from the dataset\n",
    "y_true = iris.target\n",
    "\n",
    "# Perform k-means clustering with k=5\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Extract the predicted cluster labels from the KMeans object\n",
    "y_pred = kmeans.labels_\n",
    "\n",
    "# Calculate BCubed recall\n",
    "labels = np.unique(y_true)\n",
    "recall = 0\n",
    "for label in labels:\n",
    "    idx = np.where(y_true == label)[0]\n",
    "    recall += np.sum(y_true[idx] == y_pred[idx]) / len(idx)\n",
    "recall /= len(labels)\n",
    "\n",
    "print('BCubed recall for (K = 5):', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating and evaluating the three different sizes of K, we can compare them to determine the best size based on the values of the silhouette coefficient. The silhouette coefficient provides a measure of how well each clustering solution separates the data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an array with the values of K.\n",
    "k_values = [2,4,5]\n",
    "\n",
    "#Creating an array with the values of the silhouette coefficient for each value of K respectively.\n",
    "sc_values = [S_2, s_4, S_5]\n",
    "\n",
    "#Plotting the graph.\n",
    "plt.title(\"Comparison Graph\")\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.grid(True)\n",
    "plt.plot(k_values,sc_values, 'o-')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous analysis, we have determined that the optimal number of clusters, as determined by the silhouette coefficient, is 2. This K value exhibited the highest silhouette coefficient value among all three evaluated sizes. Hence, for our dataset, the optimal K value is 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
